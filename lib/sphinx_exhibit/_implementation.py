# FIXME: Output capture.
# FIXME: Patch AbstractMovieWriter.saving.
#
# FIXME: Backreferences.
# FIXME: Generate notebook from the rst-generated html.
#
# FIXME: Upstream fix to sphinx-jinja.

import ast
from collections import ChainMap, namedtuple
import copy
from enum import Enum
import functools
import itertools
from lib2to3 import pygram
import re
from pathlib import Path
import shutil
import textwrap
import tokenize
from types import BuiltinFunctionType, FunctionType, MethodType, ModuleType
import warnings

import docutils
from docutils.parsers import rst
from docutils.statemachine import ViewList
import lxml.html
import matplotlib as mpl
import matplotlib.testing.decorators
from matplotlib import pyplot as plt
import sphinx
from sphinx.builders.dummy import DummyBuilder
from sphinx.environment import BuildEnvironment

from . import _lib2to3_parser, _offset_annotator, _util, __version__

# FIXME: Make these local to exec().
mpl.backend_bases.FigureCanvasBase.start_event_loop = (
    lambda self, timeout=0: None)
mpl.backend_bases.FigureManagerBase.show = (
    lambda self: None)

plt.switch_backend("agg")
_log = sphinx.util.logging.getLogger(__name__.split(".")[0])
_deletion_notice = """\
.. This file was autogenerated by sphinx-exhibit, and will be deleted in the
   next build.

"""


class Stage(Enum):  # backcompat: can use app.phase in sphinx>=1.8.
    RstGeneration, RstGenerated = range(2)


class Style(Enum):
    Native = "native"
    SG = "sphinx-gallery"
    None_ = "none"


State = namedtuple("State", "stage docnames backrefs")


class DocInfo:
    def __init__(self):
        # NOTE: if adding fields, update merging procedure in env_merge_info.
        self.code_line_idxs = None
        self.artefacts = None
        self.annotations = None


def builder_inited(app):
    env = BuildEnvironment(app)
    env.exhibit_state = State(Stage.RstGeneration, {}, {})
    env.find_files(app.config, DummyBuilder(app))
    exhibits = []
    for docname in env.found_docs:
        path = Path(env.doc2path(docname))
        contents = path.read_text()
        if contents.startswith(_deletion_notice):
            path.unlink()
    # Generation must happen after all the unlinking is done.
    rst.directives.register_directive("exhibit", Exhibit)
    for docname in env.found_docs:
        path = Path(env.doc2path(docname))
        try:
            contents = path.read_text()
        except FileNotFoundError:  # Could have been deleted just above.
            continue
        if re.search(r"\.\.\s+exhibit::\n", contents):
            # state.document.current_source may lose track of the original
            # document (e.g. when generating contents with .. jinja::), so
            # stash the docname in the env.
            env.prepare_settings(docname)
            docutils.core.publish_doctree(
                contents, source_path=path, settings_overrides={"env": env})
    app.env.exhibit_state = State(
        Stage.RstGenerated, env.exhibit_state.docnames, {})
    rst.directives.register_directive("exhibit-source", ExhibitSource)
    rst.directives.register_directive("exhibit-block", ExhibitBlock)
    rst.directives.register_directive("exhibit-backrefs", ExhibitBackrefs)


def split_text_and_code_blocks(src):
    tree = _lib2to3_parser.parse(src)

    def _inner():
        for i, node in enumerate(tree.children):
            if (node.type == pygram.python_symbols.simple_stmt
                    and node.children[0].type == pygram.token.STRING
                    # Exclude b- or f-strings, but not r-strings.
                    and not re.search(
                        r"""\A[^'"]*[bBfF]""", node.children[0].value)):
                # This is never the last node.
                tree.children[i + 1].prefix = (
                    node.prefix + tree.children[i + 1].prefix)
                yield ("text",
                       ast.literal_eval(
                           "".join(leaf.value for leaf in node.leaves())),
                       node.get_lineno())
            else:
                yield ("code", node, node.get_lineno())

    for tp, it_group in itertools.groupby(_inner(), lambda kv: kv[0]):
        _, strs_or_nodes, linenos = zip(*it_group)
        if tp == "text":
            string = "".join(strs_or_nodes)
        elif tp == "code":
            nodes = [*strs_or_nodes]
            # Extra newlines at the beginning or the end would be dropped
            # during the rst parsing, so drop them.  Also, extra newlines at
            # the beginning would invalidate node.get_lineno().
            nodes[0].prefix = ""
            string = "".join(map(str, nodes)).rstrip("\n") + "\n"
        yield tp, string, linenos[0]


def env_before_read_docs(app, env, docnames):
    docnames[:] = sorted(
        docnames,
        key=lambda docname: 0 if docname in env.exhibit_state.docnames else 1)


def process_py_source(
        src_path, *, syntax_style=Style.Native, output_style=Style.Native):

    with src_path.open("rb") as file:
        encoding, _ = tokenize.detect_encoding(file.readline)
    if syntax_style is Style.Native:
        with src_path.open(encoding=encoding) as file:
            src = file.read()
        text_and_code_blocks = split_text_and_code_blocks(src)
    elif syntax_style is Style.SG:
        from sphinx_gallery.py_source_parser import (
            split_code_and_text_blocks as sg_split_text_and_code_blocks)
        _, text_and_code_blocks = sg_split_text_and_code_blocks(src_path)
        # Strip extra newlines at the beginning and the end, as above.  Note
        # that s-g provides a correct lineno including the beginning newlines,
        # so it must be fixed.
        for i in range(len(text_and_code_blocks)):
            tp, string, lineno = text_and_code_blocks[i]
            if tp == "code":
                text_and_code_blocks[i] = (
                    tp,
                    string.strip("\n") + "\n",
                    lineno + len(string) - len(string.lstrip("\n")))
    else:
        assert False

    text_blocks = []
    code_line_idxs = []
    capture_after_lines = []
    block_counter = itertools.count()
    for tp, string, lineno in text_and_code_blocks:
        if tp == "text":
            text_blocks.append(string)
        elif tp == "code":
            if not string.strip():
                # Don't generate a code-block if the file ends with text.
                continue
            n_lines = string.count("\n")
            code_line_idxs.extend(range(lineno, lineno + n_lines))
            capture_after_lines.append(code_line_idxs[-1])
            text_blocks.append(".. exhibit-block:: {}"
                               .format(next(block_counter)))
            text_blocks.append(textwrap.indent(string, "   "))
        else:
            assert False

    rst_source = (_deletion_notice
                  + ":orphan:\n"
                  + "\n"
                  + ".. exhibit-source::\n"
                  + "   :source: {}\n".format(src_path)
                  + "   :capture-after-lines: {}\n".format(
                      " ".join(map(str, capture_after_lines)))
                  + "   :output-style: {}\n".format(output_style.value)
                  + "\n"
                  + "\n\n".join(text_blocks))

    return rst_source, code_line_idxs


class SourceGetterMixin(rst.Directive):
    def get_current_docname(self):
        return self.state.document.settings.env.docname

    def get_current_source(self):
        env = self.state.document.settings.env
        return (Path(env.doc2path(self.get_current_docname()))
                .relative_to(env.srcdir))


class Exhibit(SourceGetterMixin):
    option_spec = {
        "srcdir": rst.directives.unchanged_required,
        "destdir": rst.directives.unchanged_required,
        "syntax-style": Style,
        "output-style": Style,
    }
    has_content = True

    def get_src_paths_and_docnames(self):
        env = self.state.document.settings.env
        cur_dir = self.get_current_source().parent
        src_dir = env.srcdir / cur_dir / self.options["srcdir"]
        src_paths = []
        for line in self.content:
            if line.startswith("!"):
                excluded = sorted(src_dir.glob(line[1:]))
                _log.info("expanding (for removal) %s (in %s) to %s.",
                          line, src_dir.relative_to(env.srcdir),
                          " ".join(str(path.relative_to(src_dir))
                                   for path in excluded))
                for path in excluded:
                    try:
                        src_paths.remove(path)
                    except ValueError:
                        pass
            else:
                if line.startswith(r"\!"):
                    line = line[1:]
                added = sorted(src_dir.glob(line))
                _log.info("expanding (for addition) %s (in %s) to %s.",
                          line, src_dir.relative_to(env.srcdir),
                          " ".join(str(path.relative_to(src_dir))
                                   for path in added))
                src_paths.extend(added)
        return [(src_path,
                 Path(cur_dir,
                      self.options["destdir"],
                      src_path.relative_to(src_dir))
                 .with_suffix("").as_posix())
                for src_path in src_paths]

    def run(self):
        self.options.setdefault("syntax-style", Style.Native)
        self.options.setdefault("output-style", Style.Native)

        env = self.state.document.settings.env
        e_state = env.exhibit_state
        if e_state.stage is Stage.RstGeneration:
            for src_path, docname in self.get_src_paths_and_docnames():
                dest_path = Path(env.doc2path(docname))
                dest_path.parent.mkdir(parents=True, exist_ok=True)
                rst_source, code_line_idxs = process_py_source(
                    src_path,
                    syntax_style=self.options["syntax-style"],
                    output_style=self.options["output-style"])
                _util.ensure_contents(dest_path, rst_source)
                # FIXME: Also arrange to delete this file.
                shutil.copyfile(src_path, dest_path.parent / src_path.name)
                e_state.docnames[docname] = doc_info = DocInfo()
                doc_info.code_line_idxs = code_line_idxs
            return []
        elif e_state.stage is Stage.RstGenerated:
            cur_dir = self.get_current_source().parent
            vl = ViewList([
                "* :doc:`{}`".format(docname)
                for src_path, docname in self.get_src_paths_and_docnames()])
            node = rst.nodes.Element()
            self.state.nested_parse(vl, 0, node)
            return node.children
        else:
            assert False


DocRef = namedtuple("DocRef", "role lookups")
Annotation = namedtuple("Annotation", "docrefs href")


# FIXME: classmethod, staticmethod.
def get_docref(obj, source_name):
    if getattr(obj, "__name__", object()) != source_name:
        return None
    if isinstance(obj, ModuleType):
        return DocRef("py:module", (obj.__name__,))
    if not hasattr(obj, "__module__"):
        return None
    lookups = ((obj.__module__ + "." + obj.__qualname__, obj.__qualname__)
               if obj.__module__ is not None
               # Happens with extension functions, e.g. RandomState.seed.
               else (obj.__qualname__,))
    if isinstance(obj, type):
        return DocRef("py:class", lookups)
    elif (isinstance(obj, (FunctionType, BuiltinFunctionType))
          and "." not in obj.__qualname__):
        return DocRef("py:function", lookups)
    elif isinstance(obj, (MethodType, FunctionType, BuiltinFunctionType)):
        # Bound and unbound methods.
        return DocRef("py:method", lookups)
    else:
        raise TypeError(
            "Named module-level object of unknown type: {!r}".format(obj))


class ExhibitSource(SourceGetterMixin):
    option_spec = {
        "source": rst.directives.unchanged_required,
        "capture-after-lines":
            lambda s: rst.directives.positive_int_list(s) if s else [],
        "output-style": Style,
    }
    has_content = True

    def run(self):
        self.options.setdefault("output-style", Style.Native)

        env = self.state.document.settings.env
        doc_info = env.exhibit_state.docnames[self.get_current_docname()]
        doc_info.artefacts = [[] for _ in self.options["capture-after-lines"]]
        doc_info.annotations = {}

        if self.options["output-style"] is Style.None_:
            return []

        mod = _offset_annotator.parse(
            self.options["source"], doc_info.code_line_idxs)

        # Rewrite (Load context only):
        # - foo
        #   -> _sphinx_exhibit_name_(foo, "foo", offset)
        # - foo.bar
        #   -> _sphinx_exhibit_attr_(foo, "bar", offset)

        name_func_name = "!sphinx_exhibit_name"
        attr_func_name = "!sphinx_exhibit_attr"
        export_func_name = "!sphinx_exhibit_export"

        class Transformer(ast.NodeTransformer):
            def visit_Name(self, node):
                return (
                    ast.fix_missing_locations(ast.copy_location(
                        ast.Call(
                            ast.Name(name_func_name, ast.Load()),
                            [node, ast.Str(node.id), ast.Num(node.offset)],
                            []),
                        node))
                    if type(node.ctx) == ast.Load else
                    node)

            def visit_Attribute(self, node):
                self.generic_visit(node)
                return (
                    ast.fix_missing_locations(ast.copy_location(
                        ast.Call(
                            ast.Name(attr_func_name, ast.Load()),
                            [node.value, ast.Str(node.attr), ast.Num(node.offset)],
                            []),
                        node))
                    if type(node.ctx) == ast.Load else
                    node)

        mod = Transformer().visit(mod)

        for lineno in self.options["capture-after-lines"]:
            inserted = ast.fix_missing_locations(
                ast.Expr(
                    ast.Call(
                        ast.Name(export_func_name, ast.Load()),
                        [], []),
                    lineno=lineno))
            mod.body.append(inserted)
        mod.body.sort(key=lambda stmt: stmt.lineno)
        code = compile(mod, self.options["source"], "exec")

        def sphinx_exhibit_name(obj, name, offset):
            docref = get_docref(obj, name)
            if docref:
                (doc_info.annotations
                 .setdefault(offset, Annotation(set(), None))
                 .docrefs.add(docref))
            return obj

        def sphinx_exhibit_attr(obj, name, offset):
            attr = getattr(obj, name)
            docref = get_docref(attr, name)
            # FIXME: Also fetch py:attribute.
            if docref:
                (doc_info.annotations
                 .setdefault(offset, Annotation(set(), None))
                 .docrefs.add(docref))
            return attr

        sg_base_num = 0
        def sphinx_exhibit_export(
                *, _block_counter=itertools.count()):
            nonlocal sg_base_num
            block_idx = next(_block_counter)
            for fig_idx, fignum in enumerate(plt.get_fignums()):
                if self.options["output-style"] is Style.Native:
                    dest = Path(
                        env.srcdir,
                        "{}-{}-{}.png".format(env.docname, block_idx, fig_idx))
                elif self.options["output-style"] is Style.SG:
                    dir_path = (env.srcdir
                                / self.get_current_source().parent
                                / "images")
                    dir_path.mkdir(exist_ok=True)
                    dest = Path(
                        dir_path / "sphx_glr_{}_{:03}.png".format(
                            Path(env.docname).name, sg_base_num + fignum))
                else:
                    assert False
                doc_info.artefacts[block_idx].append(
                    dest.relative_to(env.srcdir))
                plt.figure(fignum).savefig(dest)
            sg_base_num += len(plt.get_fignums())
            # FIXME: Make this configurable?
            plt.close("all")

        # FIXME: chdir is only for s-g compatibility.
        # FIXME: Also patch sys.argv.
        # FIXME: runpy + override source_to_code in a custom importer.
        # Prevent Matplotlib's cleanup decorator from destroying the warnings
        # filters.
        with _util.chdir_cm(Path(self.options["source"]).parent), \
                warnings.catch_warnings():
            try:
                mpl.testing.decorators.cleanup("default")(lambda: exec(
                    code,
                    {name_func_name: sphinx_exhibit_name,
                     attr_func_name: sphinx_exhibit_attr,
                     export_func_name: sphinx_exhibit_export,
                     "__file__": self.options["source"],
                     "__name__": "__main__"}))()
            # FIXME: Report error.
            except (Exception, SystemExit):
                raise
                pass

        return []


class ExhibitBlock(SourceGetterMixin):
    required_arguments = 1
    has_content = True

    def run(self):
        e_state = self.state.document.settings.env.exhibit_state
        current_source = self.get_current_source()
        paths = (e_state.docnames[self.get_current_docname()]
                 .artefacts[int(self.arguments[0])])
        vl = ViewList(
            [".. code-block:: python", ""]
            + ["   " + line for line in self.content]
            + [""]
            + [".. image:: {}".format(path.relative_to(current_source.parent))
               for path in paths])
        node = rst.nodes.Element()
        self.state.nested_parse(vl, 0, node)
        return node.children


@functools.lru_cache()
def resolve_docrefs(env):
    """
    Resolve the runtime annotations.

    After this step, resolved annotations contain a single DocRef which
    contains a single lookup.
    """

    # Construct the merged inventory.
    inv = {}
    py_domain = "py"
    # Adapted from InventoryFile.{dump,load_v2}, without the
    # $-compression/decompression step.
    for name, dispname, role, docname, anchor, prio \
            in sorted(env.domains[py_domain].get_objects()):
        uri = env.app.builder.get_target_uri(docname)
        if anchor:
            uri += "#" + anchor
        if dispname == name:
            dispname = "-"
        inv.setdefault(py_domain + ":" + role, {})[name] = (
            env.config.project, env.config.version, uri, dispname)
    if "sphinx.ext.intersphinx" in env.config.extensions:
        for role, role_inv in env.intersphinx_inventory.items():
            inv[role] = ChainMap(inv.get(role, {}), role_inv)
    for role, role_inv in inv.items():
        suffixes_role_inv = {}
        for k, v in role_inv.items():
            parts = k.split(".")
            for i in range(len(parts)):
                suffixes_role_inv.setdefault(".".join(parts[i:]), []).append(v)
        inv[role] = ChainMap(
            role_inv,
            # Only keep unambiguous suffixes.
            {suffix: vs[0] for suffix, vs in suffixes_role_inv.items()
             if len(vs) == 1})

    def resolve_annotation(annotation):
        if len(annotation.docrefs) == 1:  # Otherwise, would be ambiguous.
            docref, = annotation.docrefs
            role_inv = inv.get(docref.role, {})
            for lookup in docref.lookups:
                try:
                    projname, version, location, dispname = role_inv[lookup]
                except KeyError:
                    continue
                return annotation._replace(
                    docrefs={docref._replace(lookups=(lookup,))},
                    href=location)
        return annotation

    # Resolve the docrefs.
    for docname, doc_info in env.exhibit_state.docnames.items():
        for offset, annotation in doc_info.annotations.items():
            if len(annotation.docrefs) == 1:  # Other annots. are ambiguous.
                docref, = annotation.docrefs
                doc_info.annotations[offset] = resolve_annotation(annotation)


@functools.lru_cache()
def compute_backrefs(env):
    for docname, doc_info in env.exhibit_state.docnames.items():
        for annotation in doc_info.annotations.values():
            if annotation.href:  # Resolved, so single values below.
                docref, = annotation.docrefs
                lookup, = docref.lookups
                (env.exhibit_state.backrefs
                 .setdefault((docref.role, lookup), set())
                 .add(docname))


class ExhibitBackrefs(rst.Directive):
    required_arguments = 2

    def run(self):
        # FIXME: Add warning if we re-run into ExhibitSource later.
        env = self.state.document.settings.env
        resolve_docrefs(env)
        compute_backrefs(env)

        role, name = self.arguments
        vl = ViewList([
            "* :doc:`{}`".format(docname)
            for docname
            in sorted(env.exhibit_state.backrefs.get((role, name)))])
        node = rst.nodes.Element()
        self.state.nested_parse(vl, 0, node)
        return node.children


def env_merge_info(app, env, docnames, other):
    for path, other_info in other.exhibit_state.paths.items():
        info = env.state.exhibit_state.paths[path]
        assert not (info.artefacts and other_info.artefacts
                    or info.annotations and other_info.annotations)
        info.artefacts = info.artefacts or other_info.artefacts
        info.annotations = info.annotations or other_info.annotations


def build_finished(app, exc):
    if exc or app.builder.name != "html":  # s-g also whitelists "readthedocs"?
        return
    for docname in app.env.exhibit_state.docnames:
        embed_annotations(app, docname)


def embed_annotations(app, docname):
    html_path = Path(app.builder.get_outfilename(docname))
    annotations = app.env.exhibit_state.docnames[docname].annotations

    rel_prefix = "../" * (len(html_path.relative_to(app.outdir).parents) - 1)
    def fix_rel_href(href):
        if "://" not in href:
            href = rel_prefix + href
        return href

    tree = lxml.html.parse(str(html_path))
    root = tree.getroot()
    elems = root.findall(
        ".//div[@class='highlight-python notranslate']/div/pre")
    offset = 0
    offset_to_elem = {}

    def visit(elem):
        nonlocal offset
        offset_to_elem[offset] = elem
        offset += len(elem.text or "")
        for child in elem:
            visit(child)
        offset += len(elem.tail or "")

    for elem in elems:
        visit(elem)

    for offset, annotation in annotations.items():
        elem = offset_to_elem[offset]
        if not annotation.href:
            continue
        assert elem.text \
            == next(iter(annotation.docrefs)).lookups[0].split(".")[-1]
        link = lxml.html.Element("a", href=fix_rel_href(annotation.href))
        link.text = elem.text
        elem.text = ""
        elem.append(link)

    tree.write(str(html_path))


def setup(app):
    app.connect("builder-inited", builder_inited)
    app.connect("env-before-read-docs", env_before_read_docs)
    app.connect("env-merge-info", env_merge_info)
    app.connect("build-finished", build_finished)
    return {"version": __version__,
            "env_version": 0,
            "parallel_read_safe": True,
            "parallel_write_safe": True}
