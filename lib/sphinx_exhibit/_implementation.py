# FIXME: Output capture.
# FIXME: Patch AbstractMovieWriter.saving.
#
# FIXME: Backreferences.
# FIXME: Generate notebook from the rst-generated html.
#
# FIXME: Upstream fix to sphinx-jinja.

import ast
from collections import ChainMap, namedtuple
import copy
from enum import Enum
import itertools
from lib2to3 import pygram
import re
from pathlib import Path
import shutil
import textwrap
import tokenize
from types import FunctionType, MethodType, ModuleType, SimpleNamespace
import warnings

import docutils
from docutils.parsers import rst
from docutils.statemachine import ViewList
import lxml.html
import matplotlib as mpl
import matplotlib.testing.decorators
from matplotlib import pyplot as plt
import sphinx
from sphinx.builders.dummy import DummyBuilder
from sphinx.environment import BuildEnvironment

from . import _lib2to3_parser, _offset_annotator, _util, __version__

# FIXME: Make these local to exec().
mpl.backend_bases.FigureCanvasBase.start_event_loop = (
    lambda self, timeout=0: None)
mpl.backend_bases.FigureManagerBase.show = (
    lambda self: None)

plt.switch_backend("agg")
_log = sphinx.util.logging.getLogger(__name__.split(".")[0])
_deletion_notice = """\
.. This file was autogenerated by sphinx-exhibit, and will be deleted in the
   next build.

"""


class Stage(Enum):  # backcompat: can use app.phase in sphinx>=1.8.
    RstGeneration, RstGenerated = range(2)


class Style(Enum):
    Native = "native"
    SG = "sphinx-gallery"
    None_ = "none"


State = namedtuple("State", "stage docnames")


class PathInfo:
    def __init__(self):
        # NOTE: if adding fields, update merging procedure in env_merge_info.
        self.code_line_idxs = None
        self.artefacts = None
        self.annotations = None


def builder_inited(app):
    env = BuildEnvironment(app)
    env.exhibit_state = State(Stage.RstGeneration, {})
    env.find_files(app.config, DummyBuilder(app))
    exhibits = []
    for docname in env.found_docs:
        path = Path(env.doc2path(docname))
        contents = path.read_text()
        if contents.startswith(_deletion_notice):
            path.unlink()
    # Generation must happen after all the unlinking is done.
    rst.directives.register_directive("exhibit", Exhibit)
    for docname in env.found_docs:
        path = Path(env.doc2path(docname))
        try:
            contents = path.read_text()
        except FileNotFoundError:  # Could have been deleted just above.
            continue
        if re.search(r"\.\.\s+exhibit::\n", contents):
            # state.document.current_source may lose track of the original
            # document (e.g. when generating contents with .. jinja::), so
            # stash the docname in the env.
            env.prepare_settings(docname)
            docutils.core.publish_doctree(
                contents, source_path=path, settings_overrides={"env": env})
    app.env.exhibit_state = State(
        Stage.RstGenerated, env.exhibit_state.docnames)
    rst.directives.register_directive("exhibit-source", ExhibitSource)
    rst.directives.register_directive("exhibit-block", ExhibitBlock)


def split_text_and_code_blocks(src):
    tree = _lib2to3_parser.parse(src)

    def _inner():
        for i, node in enumerate(tree.children):
            if (node.type == pygram.python_symbols.simple_stmt
                    and node.children[0].type == pygram.token.STRING
                    # Exclude b- or f-strings, but not r-strings.
                    and not re.search(
                        r"""\A[^'"]*[bBfF]""", node.children[0].value)):
                # This is never the last node.
                tree.children[i + 1].prefix = (
                    node.prefix + tree.children[i + 1].prefix)
                yield ("text",
                       ast.literal_eval(
                           "".join(leaf.value for leaf in node.leaves())),
                       node.get_lineno())
            else:
                yield ("code", node, node.get_lineno())

    for tp, it_group in itertools.groupby(_inner(), lambda kv: kv[0]):
        _, strs_or_nodes, linenos = zip(*it_group)
        if tp == "text":
            string = "".join(strs_or_nodes)
        elif tp == "code":
            nodes = [*strs_or_nodes]
            # Extra newlines at the beginning or the end would be dropped
            # during the rst parsing, so drop them.  Also, extra newlines at
            # the beginning would invalidate node.get_lineno().
            nodes[0].prefix = ""
            string = "".join(map(str, nodes)).rstrip("\n") + "\n"
        yield tp, string, linenos[0]


def process_py_source(
        src_path, *, syntax_style=Style.Native, output_style=Style.Native):

    with src_path.open("rb") as file:
        encoding, _ = tokenize.detect_encoding(file.readline)
    if syntax_style is Style.Native:
        with src_path.open(encoding=encoding) as file:
            src = file.read()
        text_and_code_blocks = split_text_and_code_blocks(src)
    elif syntax_style is Style.SG:
        from sphinx_gallery.py_source_parser import (
            split_code_and_text_blocks as sg_split_text_and_code_blocks)
        _, text_and_code_blocks = sg_split_text_and_code_blocks(src_path)
        # Strip extra newlines at the beginning and the end, as above.  Note
        # that s-g provides a correct lineno including the beginning newlines,
        # so it must be fixed.
        for i in range(len(text_and_code_blocks)):
            tp, string, lineno = text_and_code_blocks[i]
            if tp == "code":
                text_and_code_blocks[i] = (
                    tp,
                    string.strip("\n") + "\n",
                    lineno + len(string) - len(string.lstrip("\n")))
    else:
        assert False

    text_blocks = []
    code_line_idxs = []
    capture_after_lines = []
    block_counter = itertools.count()
    for tp, string, lineno in text_and_code_blocks:
        if tp == "text":
            text_blocks.append(string)
        elif tp == "code":
            if not string.strip():
                # Don't generate a code-block if the file ends with text.
                continue
            n_lines = string.count("\n")
            code_line_idxs.extend(range(lineno, lineno + n_lines))
            capture_after_lines.append(code_line_idxs[-1])
            text_blocks.append(".. exhibit-block:: {}"
                               .format(next(block_counter)))
            text_blocks.append(textwrap.indent(string, "   "))
        else:
            assert False

    rst_source = (_deletion_notice
                  + ":orphan:\n"
                  + "\n"
                  + ".. exhibit-source::\n"
                  # FIXME: Relative path here?
                  + "   :source: {}\n".format(src_path)
                  + "   :capture-after-lines: {}\n".format(
                      " ".join(map(str, capture_after_lines)))
                  + "   :output-style: {}\n".format(output_style.value)
                  + "\n"
                  + "\n\n".join(text_blocks))

    return rst_source, code_line_idxs


class SourceGetterMixin(rst.Directive):
    def get_current_docname(self):
        return self.state.document.settings.env.docname

    def get_current_source(self):
        return Path(self.state.document.settings.env.doc2path(
            self.get_current_docname()))


class Exhibit(SourceGetterMixin):
    option_spec = {
        "srcdir": rst.directives.unchanged_required,
        "destdir": rst.directives.unchanged_required,
        "syntax-style": Style,
        "output-style": Style,
    }
    has_content = True

    def get_src_paths_and_docnames(self):
        cur_dir = self.get_current_source().parent
        src_dir = cur_dir / self.options["srcdir"]
        src_paths = []
        for line in self.content:
            if line.startswith("!"):
                excluded = sorted(src_dir.glob(line[1:]))
                _log.info("expanding (for removal) %s (in %s) to %s.",
                          line, src_dir,
                          " ".join(str(path.relative_to(src_dir))
                                   for path in excluded))
                for path in excluded:
                    try:
                        src_paths.remove(path)
                    except ValueError:
                        pass
            else:
                if line.startswith(r"\!"):
                    line = line[1:]
                added = sorted(src_dir.glob(line))
                _log.info("expanding (for addition) %s (in %s) to %s.",
                          line, src_dir,
                          " ".join(str(path.relative_to(src_dir))
                                   for path in added))
                src_paths.extend(added)
        return [(src_path,
                 Path(self.options["destdir"], src_path.relative_to(src_dir))
                 .with_suffix("").as_posix())
                for src_path in src_paths]

    def run(self):
        self.options.setdefault("syntax-style", Style.Native)
        self.options.setdefault("output-style", Style.Native)

        env = self.state.document.settings.env
        e_state = env.exhibit_state
        if e_state.stage is Stage.RstGeneration:
            for src_path, docname in self.get_src_paths_and_docnames():
                dest_path = Path(env.doc2path(docname))
                dest_path.parent.mkdir(parents=True, exist_ok=True)
                rst_source, code_line_idxs = process_py_source(
                    src_path,
                    syntax_style=self.options["syntax-style"],
                    output_style=self.options["output-style"])
                _util.ensure_contents(dest_path, rst_source)
                # FIXME: Also arrange to delete this file.
                shutil.copyfile(src_path, dest_path.parent / src_path.name)
                e_state.docnames[docname] = path_info = PathInfo()
                path_info.code_line_idxs = code_line_idxs
            return []
        elif e_state.stage is Stage.RstGenerated:
            cur_dir = self.get_current_source().parent
            vl = ViewList([
                "* :doc:`{}`".format(docname)
                for src_path, docname in self.get_src_paths_and_docnames()])
            node = rst.nodes.Element()
            self.state.nested_parse(vl, 0, node)
            return node.children
        else:
            assert False


DocRef = namedtuple("DocRef", "role lookups")


# FIXME: classmethod, staticmethod.
def get_doc_ref(obj, source_name):
    if getattr(obj, "__name__", object()) != source_name:
        return None
    if isinstance(obj, ModuleType):
        return DocRef("py:module", [obj.__name__])
    if not hasattr(obj, "__module__"):
        return None
    lookups = [obj.__module__ + "." + obj.__qualname__,
               obj.__qualname__]
    if isinstance(obj, type):
        return DocRef("py:class", lookups)
    elif isinstance(obj, FunctionType) and "." not in obj.__qualname__:
        return DocRef("py:function", lookups)
    elif isinstance(obj, (MethodType, FunctionType)):  # also bound methods.
        return DocRef("py:method", lookups)
    else:
        raise TypeError(
            "Named module-level object of unknown type: {!r}".format(obj))


class ExhibitSource(SourceGetterMixin):
    option_spec = {
        "source": rst.directives.unchanged_required,
        "capture-after-lines":
            lambda s: rst.directives.positive_int_list(s) if s else [],
        "output-style": Style,
    }
    has_content = True

    def run(self):
        self.options.setdefault("output-style", Style.Native)

        e_state = self.state.document.settings.env.exhibit_state
        path_info = e_state.docnames[self.get_current_docname()]
        path_info.artefacts = [[] for _ in self.options["capture-after-lines"]]
        path_info.annotations = {}

        if self.options["output-style"] is Style.None_:
            return []

        mod = _offset_annotator.parse(
            self.options["source"], path_info.code_line_idxs)

        # Rewrite:
        # - foo (Load context only)
        #   -> _sphinx_exhibit_name_(foo, "foo", offset)
        # - foo.bar (any context)
        #   -> _sphinx_exhibit_attr_(foo, "bar", offset).bar
        #   (this one needs to be valid in a store context).

        class Transformer(ast.NodeTransformer):
            def visit_Name(self, node):
                return (
                    ast.fix_missing_locations(ast.copy_location(
                        ast.Call(
                            ast.Name("_sphinx_exhibit_name_", ast.Load()),
                            [node, ast.Str(node.id), ast.Num(node.offset)],
                            []),
                        node))
                    if type(node.ctx) == ast.Load else
                    node)

            def visit_Attribute(self, node):
                self.generic_visit(node)
                node.value = ast.fix_missing_locations(ast.copy_location(
                    ast.Call(
                        ast.Name("_sphinx_exhibit_attr_", ast.Load()),
                        [node.value, ast.Str(node.attr), ast.Num(node.offset)],
                        []),
                    node))
                return node

        mod = Transformer().visit(mod)

        for lineno in self.options["capture-after-lines"]:
            inserted = ast.fix_missing_locations(
                ast.Expr(
                    ast.Call(
                        ast.Name("_sphinx_exhibit_export_", ast.Load()),
                        [], []),
                    lineno=lineno))
            mod.body.append(inserted)
        mod.body.sort(key=lambda stmt: stmt.lineno)
        code = compile(mod, self.options["source"], "exec")

        def _sphinx_exhibit_name_(obj, name, offset):
            doc_ref = get_doc_ref(obj, name)
            if doc_ref:
                path_info.annotations.setdefault(offset, []).append(doc_ref)
            return obj

        def _sphinx_exhibit_attr_(obj, name, offset):
            attr = getattr(obj, name)
            doc_ref = get_doc_ref(attr, name)
            # FIXME: Also fetch py:attribute.
            if doc_ref:
                path_info.annotations.setdefault(offset, []).append(doc_ref)
            # Return a proxy object, to avoid triggering descriptors twice.
            return SimpleNamespace(**{name: attr})

        sg_base_num = 0
        def _sphinx_exhibit_export_(
                *, _block_counter=itertools.count()):
            nonlocal sg_base_num
            block_idx = next(_block_counter)
            for fig_idx, fignum in enumerate(plt.get_fignums()):
                if self.options["output-style"] is Style.Native:
                    dest = Path("{}-{}-{}.png".format(
                        self.get_current_source(), block_idx, fig_idx))
                elif self.options["output-style"] is Style.SG:
                    dir_path = self.get_current_source().parent / "images"
                    dir_path.mkdir(exist_ok=True)
                    dest = Path(
                        dir_path / "sphx_glr_{}_{:03}.png".format(
                            Path(self.state.document.settings.env.docname).name
                            .replace("/", "_"),
                            sg_base_num + fignum))
                else:
                    assert False
                path_info.artefacts[block_idx].append(dest)
                plt.figure(fignum).savefig(dest)
            sg_base_num += len(plt.get_fignums())
            # FIXME: Make this configurable?
            plt.close("all")

        # FIXME: chdir is only for s-g compatibility.
        # FIXME: Also patch sys.argv.
        # FIXME: runpy + override source_to_code in a custom importer.
        # Prevent Matplotlib's cleanup decorator from destroying the warnings
        # filters.
        with _util.chdir_cm(Path(self.options["source"]).parent), \
                warnings.catch_warnings():
            try:
                mpl.testing.decorators.cleanup("default")(lambda: exec(
                    code,
                    {"_sphinx_exhibit_name_": _sphinx_exhibit_name_,
                     "_sphinx_exhibit_attr_": _sphinx_exhibit_attr_,
                     "_sphinx_exhibit_export_": _sphinx_exhibit_export_,
                     "__file__": self.options["source"],
                     "__name__": "__main__"}))()
            # FIXME: Report error.
            except (Exception, SystemExit):
                raise
                pass

        return []


class ExhibitBlock(SourceGetterMixin):
    required_arguments = 1
    has_content = True

    def run(self):
        e_state = self.state.document.settings.env.exhibit_state
        current_source = self.get_current_source()
        paths = (e_state.docnames[self.get_current_docname()]
                 .artefacts[int(self.arguments[0])])
        vl = ViewList(
            [".. code-block:: python", ""]
            + ["   " + line for line in self.content]
            + [""]
            + [".. image:: {}".format(path.relative_to(current_source.parent))
               for path in paths])
        node = rst.nodes.Element()
        self.state.nested_parse(vl, 0, node)
        return node.children


def env_merge_info(app, env, docnames, other):
    for path, other_info in other.exhibit_state.paths.items():
        this_info = env.state.exhibit_state.paths[path]
        assert not (this_info.artefacts and other_info.artefacts
                    or this_info.annotations and other_info.annotations)
        this_info.artefacts = this_info.artefacts or other_info.artefacts
        this_info.annotations = this_info.annotations or other_info.annotations


def build_finished(app, exc):
    if exc or app.builder.name != "html":  # s-g also whitelists "readthedocs"?
        return
    inv = {}
    py_domain = "py"
    # Adapted from InventoryFile.{dump,load_v2}, without the
    # $-compression/decompression step.
    for name, dispname, role, docname, anchor, prio \
            in sorted(app.env.domains[py_domain].get_objects()):
        uri = app.builder.get_target_uri(docname)
        if anchor:
            uri += "#" + anchor
        if dispname == name:
            dispname = "-"
        inv.setdefault(py_domain + ":" + role, {})[name] = (
            app.env.config.project, app.env.config.version, uri, dispname)
    if "sphinx.ext.intersphinx" in app.env.config.extensions:
        for role, role_inv in app.env.intersphinx_inventory.items():
            inv[role] = ChainMap(inv.get(role, {}), role_inv)
    for role, role_inv in inv.items():
        suffixes_role_inv = {}
        for k, v in role_inv.items():
            parts = k.split(".")
            for i in range(len(parts)):
                suffixes_role_inv.setdefault(".".join(parts[i:]), []).append(v)
        inv[role] = ChainMap(
            role_inv,
            # Only keep unambiguous suffixes.
            {suffix: vs[0] for suffix, vs in suffixes_role_inv.items()
             if len(vs) == 1})
    for docname in app.env.exhibit_state.docnames:
        embed_annotations(app, inv, docname)


def lookup_href(inv, doc_ref):
    role_inv = inv[doc_ref.role]
    entry = next(filter(None,
                        (role_inv.get(lookup) for lookup in doc_ref.lookups)),
                 None)
    if entry:
        projname, version, location, dispname = entry
        return location


def embed_annotations(app, inv, docname):
    html_path = Path(app.outdir, docname).with_suffix(".html")
    annotations = app.env.exhibit_state.docnames[docname].annotations

    rel_prefix = "../" * (len(html_path.relative_to(app.outdir).parents) - 1)
    def fix_rel_href(href):
        if "://" not in href:
            href = rel_prefix + href
        return href

    tree = lxml.html.parse(str(html_path))
    root = tree.getroot()
    elems = root.findall(
        ".//div[@class='highlight-python notranslate']/div/pre")
    offset = 0
    offset_to_elem = {}

    def visit(elem, _depth=0):
        nonlocal offset
        offset_to_elem[offset] = elem
        offset += len(elem.text or "")
        for child in elem:
            visit(child, _depth+1)
        offset += len(elem.tail or "")

    for elem in elems:
        visit(elem)

    for offset, doc_refs in annotations.items():
        if len(doc_refs) == 1:
            elem = offset_to_elem[offset]
            doc_ref, = doc_refs
            href = lookup_href(inv, doc_ref)
            if not href:
                continue
            assert elem.text == doc_ref.lookups[0].split(".")[-1]
            link = lxml.html.Element("a", href=fix_rel_href(href))
            link.text = elem.text
            elem.text = ""
            elem.append(link)

    tree.write(str(html_path))


def setup(app):
    app.connect("builder-inited", builder_inited)
    app.connect("env-merge-info", env_merge_info)
    app.connect("build-finished", build_finished)
    return {"version": __version__,
            "env_version": 0,
            "parallel_read_safe": True,
            "parallel_write_safe": True}
